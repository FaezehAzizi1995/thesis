# -*- coding: utf-8 -*-
"""jshannon distance close works.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jc_35B8fEPfBxybFielRejC8vnNB24U_

# **2 kMeans**
"""

import pandas as pd

embeddings=pd.read_csv('w.txt', sep='\t', header=0,encoding='UTF-8')

print(embeddings[:121])

import umap
umap_embeddings = umap.UMAP(n_neighbors=15, n_components=5, metric='cosine').fit_transform(embeddings)
#کاهش بعد به 5---همسایه های محلی 15

#print(umap_embeddings)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

feature_columns = ['1','2','3'	,'4'	,'5'	,'6',	'7',	'8',	'9',	'10',	'11',	'12',	'13',	'14',	'15',	'16',	'17',
                   '18',	'19',	'20',	'21',	'22',	'23',	'24',	'25',	'26',	'27',	'28',	'29',	'30',	'31',	'32',	'33',
                   '34',	'35',	'36',	'37',	'38',	'39',	'40',	'41',	'42',	'43',	'44',	'45',	'46',	'47',	'48',	'49',
                   '50',	'51',	'52',	'53',	'54',	'55',	'56',	'57',	'58',	'59',	'60',	'61',	'62',	'63',	'64',	'65',
                   '66',	'67',	'68',	'69',	'70',	'71',	'72',	'73',	'74',	'75',	'76',	'77',	'78',	'79',	'80',	'81',
                   '82',	'83',	'84',	'85',	'86',	'87',	'88',	'89',	'90',	'91',	'92',	'93', '94',	'95',	'96',	'97',
                   '98',	'99',	'100',	'101'	,'102',	'103',	'104',	'105',	'106',	'107',	'108',	'109',	'110',
                   '111',	'112',	'113',	'114',	'115',	'116',	'117',	'118',	'119',	'120']

X = embeddings[feature_columns]

from sklearn.cluster import KMeans
from sklearn.metrics import davies_bouldin_score

#from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters = 4, max_iter = 300, random_state = 0)
kmeans.fit(X)

results = {}
import scipy.stats
import scipy.spatial
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt
import pandas as pd
# Prepare data


for i in range(0,30):
  umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
  result = pd.DataFrame(umap_data, columns=['x', 'y'])
  js_distance_scipy = scipy.spatial.distance.jensenshannon(result.x, result.y)
  print(js_distance_scipy)
  results.update({i: js_distance_scipy})
#result['labels'] = kmeans.labels_

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Jensen-Shannon Distance")
plt.show()

centers = kmeans.cluster_centers_
#print(centers)

kmeans.labels_

print(kmeans.labels_)

#from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(umap_embeddings, kmeans.labels_)
print(db_index)

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(umap_embeddings)
    umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
    result = pd.DataFrame(umap_data, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
    print(db_index)
    results.update({i: db_index})

    #kmeans = KMeans(n_clusters=i, random_state=30)
   # labels= kmeans.fit_predict(umap_embeddings)
  #  db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
   # results.update({i: db_index})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Davies-Bouldin")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
# %matplotlib inline

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(umap_embeddings)
   # cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
    umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
    result = pd.DataFrame(umap_data, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    #db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
    silhouette = silhouette_score(umap_embeddings, cluster.labels_)
    print(silhouette)
    results.update({i: silhouette})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Silhouette")
plt.show()

from sklearn import metrics

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(umap_embeddings)
   # cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
    umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
    result = pd.DataFrame(umap_data, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    #db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
    #silhouette = silhouette_score(umap_embeddings, cluster.labels_)
    CH = metrics.calinski_harabasz_score(umap_embeddings, cluster.labels_)
    print(CH)
    results.update({i: CH})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Calinski Harabasz")
plt.show()

# Visualize clusters
fig, ax = plt.subplots(figsize=(10, 10))
outliers = result.loc[result.labels == -1, :]
clustered = result.loc[result.labels != -1, :]
plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)
plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')
plt.colorbar()
plt.savefig('myfig.png')

sse = []
for K in range(1, 10):
    model = KMeans(n_clusters=K)
    model.fit(X)
    sse.append(model.inertia_)

sse = model.inertia_

print(sse)

import matplotlib.pyplot as plt
import pandas as pd
plt.plot(sse)
plt.xlabel("K ")
plt.ylabel("Elbow")
plt.show()

"""# **BEFORE UMAP**"""

embedd=list()

import pandas as pd

embedd=pd.read_csv('w.txt', sep='\t', header=0,encoding='UTF-8')

#print(embedd[:121])

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

feature_columns = ['1','2','3'	,'4'	,'5'	,'6',	'7',	'8',	'9',	'10',	'11',	'12',	'13',	'14',	'15',	'16',	'17',
                   '18',	'19',	'20',	'21',	'22',	'23',	'24',	'25',	'26',	'27',	'28',	'29',	'30',	'31',	'32',	'33',
                   '34',	'35',	'36',	'37',	'38',	'39',	'40',	'41',	'42',	'43',	'44',	'45',	'46',	'47',	'48',	'49',
                   '50',	'51',	'52',	'53',	'54',	'55',	'56',	'57',	'58',	'59',	'60',	'61',	'62',	'63',	'64',	'65',
                   '66',	'67',	'68',	'69',	'70',	'71',	'72',	'73',	'74',	'75',	'76',	'77',	'78',	'79',	'80',	'81',
                   '82',	'83',	'84',	'85',	'86',	'87',	'88',	'89',	'90',	'91',	'92',	'93', '94',	'95',	'96',	'97',
                   '98',	'99',	'100',	'101'	,'102',	'103',	'104',	'105',	'106',	'107',	'108',	'109',	'110',
                   '111',	'112',	'113',	'114',	'115',	'116',	'117',	'118',	'119',	'120']

Z = embedd[feature_columns]

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters = 4, max_iter = 300, random_state = 0)
kmeans.fit(Z)

centers = kmeans.cluster_centers_
#print(centers)

kmeans.labels_

from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(embedd, kmeans.labels_)
print(db_index)

print(len(embedd))

print(len(kmeans.labels_))

#print(embedd)

import matplotlib.pyplot as plt
import pandas as pd
# Prepare data
##umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings) #کاهش بعد به 2
result = pd.DataFrame(embedd, columns=['x', 'y'])
result['labels'] = kmeans.labels_

print(len(embedd))

print(len(kmeans.labels_))

print(kmeans.labels_)

from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(embedd, kmeans.labels_)
print(db_index)

#import hdbscan
#cluster = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
#import matplotlib.pyplot as plt
#import pandas as pd
# Prepare data
#umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings) #کاهش بعد به 2
#result = pd.DataFrame(umap_data, columns=['x', 'y'])
#result['labels'] = cluster.labels_

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(embedd)
   # cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
   # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embedding)
    result = pd.DataFrame(embedd, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    db_index = davies_bouldin_score(embedd, cluster.labels_)
    print(db_index)
    results.update({i: db_index})

    #kmeans = KMeans(n_clusters=i, random_state=30)
   # labels= kmeans.fit_predict(umap_embeddings)
  #  db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
   # results.update({i: db_index})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Davies-Boulding Index")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
# %matplotlib inline

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(embedd)
   # cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
  #  umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
    result = pd.DataFrame(embedd, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    #db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
    silhouette = silhouette_score(embedd, cluster.labels_)
    print(silhouette)
    results.update({i: silhouette})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Silhouette")
plt.show()

from sklearn import metrics

results = {}

for i in range(3,10):
    cluster = KMeans(n_clusters = i, max_iter = 300, random_state = 0).fit(embedd)
   # cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)
   # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
    result = pd.DataFrame(embedd, columns=['x', 'y'])
    result['labels'] = cluster.labels_
    #db_index = davies_bouldin_score(umap_embeddings, cluster.labels_)
    #silhouette = silhouette_score(umap_embeddings, cluster.labels_)
    CH = metrics.calinski_harabasz_score(embedd, cluster.labels_)
    print(CH)
    results.update({i: CH})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Calinski Harabasz")
plt.show()

# Visualize clusters
fig, ax = plt.subplots(figsize=(10, 10))
outliers = result.loc[result.labels == -1, :]
clustered = result.loc[result.labels != -1, :]
plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)
plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')
plt.colorbar()
plt.savefig('myfig.png')

sse = model.inertia_

sse = []
for K in range(1, 10):
    model = KMeans(n_clusters=K)
    model.fit(Z)
    sse.append(model.inertia_)

print(sse)

import matplotlib.pyplot as plt
import pandas as pd
plt.plot(sse)
plt.xlabel("K ")
plt.ylabel("Elbow")
plt.show()

print(len(cluster.labels_))

print(cluster.labels_)

"""# **اقلیدسیCLOSE WORK**

```
# This is formatted as code
```


"""

embedd=list()

import pandas as pd

embedd=pd.read_csv('نسبت موضووع ب کشور.txt', sep='\t', header=0,encoding='UTF-8')

#print(embedd[:121])

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

feature_columns = ['1','2','3'	,'4'	,'5'	,'6',	'7',	'8',	'9',	'10']

Z = embedd[feature_columns]

import pandas as pd
import numpy as np

from sklearn.cluster import AgglomerativeClustering
model = AgglomerativeClustering(distance_threshold=0.2, n_clusters=None, metric='euclidean')

model = model.fit(Z)

model.labels_  #####

results = {}
import scipy.stats
import scipy.spatial
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt
import pandas as pd
# Prepare data


for i in range(0,30):
 #  umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
  result = pd.DataFrame(embedd, columns=['x', 'y'])
  js_distance_scipy = scipy.spatial.distance.jensenshannon(result.x, result.y)
  print(js_distance_scipy)
  results.update({i: js_distance_scipy})
#result['labels'] = kmeans.labels_

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Jensen-Shannon Distance")
plt.show()

# Number of clusters
model.n_clusters_
#50
# Distances between clusters
distances = model.distances_
distances.min()
#0.09999999999999964
distances.max()
#3.828052620290243

from scipy.cluster.hierarchy import dendrogram
from scipy.cluster import hierarchy

ZZ = hierarchy.linkage(model.children_, 'ward')
print(ZZ)

from matplotlib import pyplot as plt
plt.figure(figsize=(10,10))
dn = hierarchy.dendrogram(ZZ)
#print(dn)

import matplotlib.pyplot as plt
import pandas as pd
# Prepare data
##umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings) #کاهش بعد به 2
result = pd.DataFrame(embedd, columns=['x', 'y'])
result['labels'] = model.labels_

from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(embedd, model.labels_)
print(db_index)

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   db_index = davies_bouldin_score(embedd, cluster.labels_)
   print(db_index)
   results.update({i: db_index})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Davies-Boulding Index")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.metrics import silhouette_score
# %matplotlib inline

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   silhouette = silhouette_score(embedd, cluster.labels_)
   print(silhouette)
   results.update({i: silhouette})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Silhouette")
plt.show()

from sklearn import metrics

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   CH = metrics.calinski_harabasz_score(embedd, cluster.labels_)
   print(CH)
   results.update({i: CH})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Calinski Harabasz")
plt.show()

"""# #JSD"""

embedd=list()

import pandas as pd

embedd=pd.read_csv('نسبت موضووع ب کشور.txt', sep='\t', header=0,encoding='UTF-8')

#print(embedd[:121])

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

feature_columns = ['1','2','3'	,'4'	,'5'	,'6',	'7',	'8',	'9',	'10']

Z = embedd[feature_columns]

import pandas as pd
import numpy as np

from scipy.spatial.distance import jensenshannon

from sklearn.cluster import AgglomerativeClustering
model = AgglomerativeClustering(distance_threshold=0.2, n_clusters=None, metric='precomputed', linkage='complete')

model = model.fit(Z)

model.labels_  #####

results = {}
import scipy.stats
import scipy.spatial
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt
import pandas as pd
# Prepare data


for i in range(0,30):
 #  umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
  result = pd.DataFrame(embedd, columns=['x', 'y'])
  js_distance_scipy = scipy.spatial.distance.jensenshannon(result.x, result.y)
  print(js_distance_scipy)
  results.update({i: js_distance_scipy})
#result['labels'] = kmeans.labels_

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Jensen-Shannon Distance")
plt.show()

# Number of clusters
model.n_clusters_
#50
# Distances between clusters
distances = model.distances_
distances.min()
#0.09999999999999964
distances.max()
#3.828052620290243

from scipy.cluster.hierarchy import dendrogram
from scipy.cluster import hierarchy

ZZ = hierarchy.linkage(model.children_, 'ward')
print(ZZ)

from matplotlib import pyplot as plt
plt.figure(figsize=(10,10))
dn = hierarchy.dendrogram(ZZ)
#print(dn)

import matplotlib.pyplot as plt
import pandas as pd
# Prepare data
##umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings) #کاهش بعد به 2
result = pd.DataFrame(embedd, columns=['x', 'y'])
result['labels'] = model.labels_

from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(embedd, model.labels_)
print(db_index)

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   db_index = davies_bouldin_score(embedd, cluster.labels_)
   print(db_index)
   results.update({i: db_index})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Davies-Boulding Index")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.metrics import silhouette_score
# %matplotlib inline

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   silhouette = silhouette_score(embedd, cluster.labels_)
   print(silhouette)
   results.update({i: silhouette})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Silhouette")
plt.show()

from sklearn import metrics

results = {}

for i in range(3,10):
   cluster = AgglomerativeClustering(distance_threshold=None, n_clusters=i)
   cluster = cluster.fit(Z.to_numpy())

  # umap_data = umap.UMAP(n_neighbors=2, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
   result = pd.DataFrame(embedd, columns=['x', 'y'])
  # print(cluster.labels_)
   result['labels'] = cluster.labels_
   CH = metrics.calinski_harabasz_score(embedd, cluster.labels_)
   print(CH)
   results.update({i: CH})

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Calinski Harabasz")
plt.show()

"""# JSD INTRO"""

import numpy as np
import scipy as sp

def jsd(p, q, base=np.e):
    '''
        Implementation of pairwise `jsd` based on
        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence
    '''
    ## convert to np.array
    p, q = np.asarray(p), np.asarray(q)
    ## normalize p, q to probabilities
    p, q = p/p.sum(), q/q.sum()
    m = 1./2*(p + q)
    return sp.stats.entropy(p,m, base=base)/2. +  sp.stats.entropy(q, m, base=base)/2.

results = {}
import scipy.stats
import scipy.spatial
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt
import pandas as pd
# Prepare data


for i in range(0,30):
 #  umap_data = umap.UMAP(n_neighbors=3, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)
  result = pd.DataFrame(embedd, columns=['x', 'y'])
  js_distance_scipy = scipy.spatial.distance.jensenshannon(result.x, result.y)
  print(js_distance_scipy)
  results.update({i: js_distance_scipy})
#result['labels'] = kmeans.labels_

plt.plot(list(results.keys()), list(results.values()))
plt.xlabel("k")
plt.ylabel("Jensen-Shannon Distance")
plt.show()

"""# az **inja**"""

from scipy.spatial import distance
import numpy as np
distance.jensenshannon([1.0, 0.0, 0.0], [0.0, 1.0, 0.0], 2.0)

distance.jensenshannon([1.0, 0.0], [0.5, 0.5])

distance.jensenshannon([1.0, 0.0, 0.0], [1.0, 2.0, 3.0])

#####################################################################2
a = np.array([[0.068514802,	0.062254323,	0.05962231,	0.119691305,	0.071583194,	0.080015256,	0.119155282,	0.067147255,	0.105297699,	0.246718574],
[0.066385044,	0.097953523,	0.053812396,	0.102643176,	0.081585358,	0.072178681,	0.073611124,	0.083647345,	0.119111703,	0.249071649],
[0.09916697,	0.095837858,	0.095725134,	0.099674228,	0.099302239,	0.105656109,	0.098381661,	0.096818556,	0.103390359,	0.106046886],
[0.070983677,	0.060003222,	0.055734536,	0.125080541,	0.100515464,	0.074715421,	0.08225945,	0.059063574,	0.090045103,	0.281599012],
[0.070118745,	0.063065836,	0.059372676,	0.124541561,	0.112487497,	0.077658947,	0.08660973,	0.062475956,	0.117001359,	0.226667693],
[0.064220498,	0.056600535,	0.054747031,	0.118692936,	0.08677147,	0.073041807,	0.093601977,	0.061131324,	0.08759525,	0.303597172],
[0.071917808,	0.056056236,	0.055515501,	0.091384283,	0.091925018,	0.078046143,	0.086697909,	0.08777938,	0.120764239,	0.259913482],
[0.100953312,	0.053043266,	0.054998778,	0.103153263,	0.093131264,	0.077242728,	0.090686874,	0.055487656,	0.128330482,	0.242972378],
[0.070305802,	0.060302944,	0.058016576,	0.112317805,	0.071163189,	0.076307516,	0.11546156,	0.070877394,	0.108888254,	0.25635896],
[0.073607613,	0.063532046,	0.060453401,	0.116428771,	0.077805765,	0.082843549,	0.100475791,	0.063252169,	0.091519731,	0.270081164],
[0.069148936,	0.068794326,	0.067375887,	0.113475177,	0.087943262,	0.087234043,	0.09929078,	0.068439716,	0.09822695,	0.240070922],
[0.08264136,	0.06405694,	0.065243179,	0.135231317,	0.0838276,	0.086595492,	0.092922104,	0.074733096,	0.088967972,	0.225780941],
[0.081471748,	0.073587385,	0.069645204,	0.109505037,	0.084537889,	0.085851949,	0.083661848,	0.074025405,	0.095926413,	0.241787122],
[0.074699867,	0.067585594,	0.067140952,	0.116051578,	0.078257003,	0.083592708,	0.112494442,	0.06891952,	0.160071143,	0.171187194],
[0.068554396,	0.056631893,	0.054644809,	0.128663686,	0.070044709,	0.097863885,	0.071038251,	0.063089916,	0.143070045,	0.24639841],
[0.059907834,	0.050691244,	0.048963134,	0.100230415,	0.067396313,	0.059331797,	0.178571429,	0.049539171,	0.185483871,	0.199884793],
])
b = np.array([[0.067993367,	0.063018242,	0.068546158,	0.092316197,	0.077390824,	0.07628524,	0.089552239,	0.061359867,	0.202874516,	0.20066335],
[0.083210604,	0.066273932,	0.070692194,	0.086156112,	0.086156112,	0.125184094,	0.075110457,	0.07437408,	0.201030928,	0.131811487],
[0.061403509,	0.05628655,	0.054824561,	0.100146199,	0.093567251,	0.07748538,	0.076754386,	0.060672515,	0.099415205,	0.319444444],
[0.089992242,	0.086113266,	0.068269977,	0.112490303,	0.104732351,	0.10007758,	0.113266098,	0.076803724,	0.099301784,	0.148952676],
[0.074979625,	0.064384678,	0.065199674,	0.108394458,	0.096169519,	0.077424613,	0.100244499,	0.066829666,	0.147514262,	0.198859006],
[0.088937093,	0.066160521,	0.057483731,	0.127982646,	0.077006508,	0.07483731,	0.092190889,	0.061822126,	0.090021692,	0.263557484],
[0.08993576,	0.065310493,	0.066381156,	0.099571734,	0.08137045,	0.087794433,	0.084582441,	0.071734475,	0.113490364,	0.239828694],
[0.068852459,	0.061202186,	0.06010929,	0.112568306,	0.096174863,	0.083060109,	0.089617486,	0.063387978,	0.084153005,	0.280874317],
[0.075949367,	0.067510549,	0.066104079,	0.113924051,	0.077355837,	0.078762307,	0.105485232,	0.067510549,	0.108298172,	0.239099859],
[0.064971751,	0.060734463,	0.056497175,	0.097457627,	0.103107345,	0.079096045,	0.104519774,	0.062146893,	0.072033898,	0.299435028],
[0.077531646,	0.068037975,	0.066455696,	0.113924051,	0.083860759,	0.085443038,	0.077531646,	0.071202532,	0.096518987,	0.259493671],
[0.078066914,	0.066914498,	0.063197026,	0.109665428,	0.094795539,	0.117100372,	0.078066914,	0.068773234,	0.079925651,	0.243494424],
[0.074226804,	0.065979381,	0.068041237,	0.115463918,	0.080412371,	0.074226804,	0.084536082,	0.070103093,	0.117525773,	0.249484536],
[0.068965517,	0.068965517,	0.066502463,	0.113300493,	0.088669951,	0.078817734,	0.081280788,	0.064039409,	0.098522167,	0.270935961],
[0.074850299,	0.071856287,	0.068862275,	0.116766467,	0.095808383,	0.086826347,	0.077844311,	0.071856287,	0.095808383,	0.239520958],
[0.080168776,	0.080168776,	0.075949367,	0.130801688,	0.080168776,	0.084388186,	0.084388186,	0.084388186,	0.097046414,	0.202531646],])

x=list()

for i in range(16):
  for j in range(16):
    x=distance.jensenshannon(a[i], b[j], axis=0)
    print(x, '      i=' ,i ,'        j=', j)

#####################################################################2
a = np.array([[0.068514802,	0.062254323,	0.05962231,	0.119691305,	0.071583194,	0.080015256,	0.119155282,	0.067147255,	0.105297699,	0.246718574],
[0.066385044,	0.097953523,	0.053812396,	0.102643176,	0.081585358,	0.072178681,	0.073611124,	0.083647345,	0.119111703,	0.249071649],
[0.09916697,	0.095837858,	0.095725134,	0.099674228,	0.099302239,	0.105656109,	0.098381661,	0.096818556,	0.103390359,	0.106046886],
[0.070983677,	0.060003222,	0.055734536,	0.125080541,	0.100515464,	0.074715421,	0.08225945,	0.059063574,	0.090045103,	0.281599012],
[0.070118745,	0.063065836,	0.059372676,	0.124541561,	0.112487497,	0.077658947,	0.08660973,	0.062475956,	0.117001359,	0.226667693],
[0.064220498,	0.056600535,	0.054747031,	0.118692936,	0.08677147,	0.073041807,	0.093601977,	0.061131324,	0.08759525,	0.303597172],
[0.071917808,	0.056056236,	0.055515501,	0.091384283,	0.091925018,	0.078046143,	0.086697909,	0.08777938,	0.120764239,	0.259913482],
[0.100953312,	0.053043266,	0.054998778,	0.103153263,	0.093131264,	0.077242728,	0.090686874,	0.055487656,	0.128330482,	0.242972378],
[0.070305802,	0.060302944,	0.058016576,	0.112317805,	0.071163189,	0.076307516,	0.11546156,	0.070877394,	0.108888254,	0.25635896],
[0.073607613,	0.063532046,	0.060453401,	0.116428771,	0.077805765,	0.082843549,	0.100475791,	0.063252169,	0.091519731,	0.270081164],
[0.069148936,	0.068794326,	0.067375887,	0.113475177,	0.087943262,	0.087234043,	0.09929078,	0.068439716,	0.09822695,	0.240070922],
[0.08264136,	0.06405694,	0.065243179,	0.135231317,	0.0838276,	0.086595492,	0.092922104,	0.074733096,	0.088967972,	0.225780941],
[0.081471748,	0.073587385,	0.069645204,	0.109505037,	0.084537889,	0.085851949,	0.083661848,	0.074025405,	0.095926413,	0.241787122],
[0.074699867,	0.067585594,	0.067140952,	0.116051578,	0.078257003,	0.083592708,	0.112494442,	0.06891952,	0.160071143,	0.171187194],
[0.068554396,	0.056631893,	0.054644809,	0.128663686,	0.070044709,	0.097863885,	0.071038251,	0.063089916,	0.143070045,	0.24639841],
[0.059907834,	0.050691244,	0.048963134,	0.100230415,	0.067396313,	0.059331797,	0.178571429,	0.049539171,	0.185483871,	0.199884793],
])
b = np.array([[0.067993367,	0.063018242,	0.068546158,	0.092316197,	0.077390824,	0.07628524,	0.089552239,	0.061359867,	0.202874516,	0.20066335],
[0.083210604,	0.066273932,	0.070692194,	0.086156112,	0.086156112,	0.125184094,	0.075110457,	0.07437408,	0.201030928,	0.131811487],
[0.061403509,	0.05628655,	0.054824561,	0.100146199,	0.093567251,	0.07748538,	0.076754386,	0.060672515,	0.099415205,	0.319444444],
[0.089992242,	0.086113266,	0.068269977,	0.112490303,	0.104732351,	0.10007758,	0.113266098,	0.076803724,	0.099301784,	0.148952676],
[0.074979625,	0.064384678,	0.065199674,	0.108394458,	0.096169519,	0.077424613,	0.100244499,	0.066829666,	0.147514262,	0.198859006],
[0.088937093,	0.066160521,	0.057483731,	0.127982646,	0.077006508,	0.07483731,	0.092190889,	0.061822126,	0.090021692,	0.263557484],
[0.08993576,	0.065310493,	0.066381156,	0.099571734,	0.08137045,	0.087794433,	0.084582441,	0.071734475,	0.113490364,	0.239828694],
[0.068852459,	0.061202186,	0.06010929,	0.112568306,	0.096174863,	0.083060109,	0.089617486,	0.063387978,	0.084153005,	0.280874317],
[0.075949367,	0.067510549,	0.066104079,	0.113924051,	0.077355837,	0.078762307,	0.105485232,	0.067510549,	0.108298172,	0.239099859],
[0.064971751,	0.060734463,	0.056497175,	0.097457627,	0.103107345,	0.079096045,	0.104519774,	0.062146893,	0.072033898,	0.299435028],
[0.077531646,	0.068037975,	0.066455696,	0.113924051,	0.083860759,	0.085443038,	0.077531646,	0.071202532,	0.096518987,	0.259493671],
[0.078066914,	0.066914498,	0.063197026,	0.109665428,	0.094795539,	0.117100372,	0.078066914,	0.068773234,	0.079925651,	0.243494424],
[0.074226804,	0.065979381,	0.068041237,	0.115463918,	0.080412371,	0.074226804,	0.084536082,	0.070103093,	0.117525773,	0.249484536],
[0.068965517,	0.068965517,	0.066502463,	0.113300493,	0.088669951,	0.078817734,	0.081280788,	0.064039409,	0.098522167,	0.270935961],
[0.074850299,	0.071856287,	0.068862275,	0.116766467,	0.095808383,	0.086826347,	0.077844311,	0.071856287,	0.095808383,	0.239520958],
[0.080168776,	0.080168776,	0.075949367,	0.130801688,	0.080168776,	0.084388186,	0.084388186,	0.084388186,	0.097046414,	0.202531646],])

x=list()

for i in range(16):
  for j in range(16):
    x=distance.jensenshannon(a[i], a[j], axis=0)
    print(x, '      i=' ,i ,'        i+1=', j)

#####################################################################2
a = np.array([[0.068514802,	0.062254323,	0.05962231,	0.119691305,	0.071583194,	0.080015256,	0.119155282,	0.067147255,	0.105297699,	0.246718574],
[0.066385044,	0.097953523,	0.053812396,	0.102643176,	0.081585358,	0.072178681,	0.073611124,	0.083647345,	0.119111703,	0.249071649],
[0.09916697,	0.095837858,	0.095725134,	0.099674228,	0.099302239,	0.105656109,	0.098381661,	0.096818556,	0.103390359,	0.106046886],
[0.070983677,	0.060003222,	0.055734536,	0.125080541,	0.100515464,	0.074715421,	0.08225945,	0.059063574,	0.090045103,	0.281599012],
[0.070118745,	0.063065836,	0.059372676,	0.124541561,	0.112487497,	0.077658947,	0.08660973,	0.062475956,	0.117001359,	0.226667693],
[0.064220498,	0.056600535,	0.054747031,	0.118692936,	0.08677147,	0.073041807,	0.093601977,	0.061131324,	0.08759525,	0.303597172],
[0.071917808,	0.056056236,	0.055515501,	0.091384283,	0.091925018,	0.078046143,	0.086697909,	0.08777938,	0.120764239,	0.259913482],
[0.100953312,	0.053043266,	0.054998778,	0.103153263,	0.093131264,	0.077242728,	0.090686874,	0.055487656,	0.128330482,	0.242972378],
[0.070305802,	0.060302944,	0.058016576,	0.112317805,	0.071163189,	0.076307516,	0.11546156,	0.070877394,	0.108888254,	0.25635896],
[0.073607613,	0.063532046,	0.060453401,	0.116428771,	0.077805765,	0.082843549,	0.100475791,	0.063252169,	0.091519731,	0.270081164],
[0.069148936,	0.068794326,	0.067375887,	0.113475177,	0.087943262,	0.087234043,	0.09929078,	0.068439716,	0.09822695,	0.240070922],
[0.08264136,	0.06405694,	0.065243179,	0.135231317,	0.0838276,	0.086595492,	0.092922104,	0.074733096,	0.088967972,	0.225780941],
[0.081471748,	0.073587385,	0.069645204,	0.109505037,	0.084537889,	0.085851949,	0.083661848,	0.074025405,	0.095926413,	0.241787122],
[0.074699867,	0.067585594,	0.067140952,	0.116051578,	0.078257003,	0.083592708,	0.112494442,	0.06891952,	0.160071143,	0.171187194],
[0.068554396,	0.056631893,	0.054644809,	0.128663686,	0.070044709,	0.097863885,	0.071038251,	0.063089916,	0.143070045,	0.24639841],
[0.059907834,	0.050691244,	0.048963134,	0.100230415,	0.067396313,	0.059331797,	0.178571429,	0.049539171,	0.185483871,	0.199884793],
])
b = np.array([[0.067993367,	0.063018242,	0.068546158,	0.092316197,	0.077390824,	0.07628524,	0.089552239,	0.061359867,	0.202874516,	0.20066335],
[0.083210604,	0.066273932,	0.070692194,	0.086156112,	0.086156112,	0.125184094,	0.075110457,	0.07437408,	0.201030928,	0.131811487],
[0.061403509,	0.05628655,	0.054824561,	0.100146199,	0.093567251,	0.07748538,	0.076754386,	0.060672515,	0.099415205,	0.319444444],
[0.089992242,	0.086113266,	0.068269977,	0.112490303,	0.104732351,	0.10007758,	0.113266098,	0.076803724,	0.099301784,	0.148952676],
[0.074979625,	0.064384678,	0.065199674,	0.108394458,	0.096169519,	0.077424613,	0.100244499,	0.066829666,	0.147514262,	0.198859006],
[0.088937093,	0.066160521,	0.057483731,	0.127982646,	0.077006508,	0.07483731,	0.092190889,	0.061822126,	0.090021692,	0.263557484],
[0.08993576,	0.065310493,	0.066381156,	0.099571734,	0.08137045,	0.087794433,	0.084582441,	0.071734475,	0.113490364,	0.239828694],
[0.068852459,	0.061202186,	0.06010929,	0.112568306,	0.096174863,	0.083060109,	0.089617486,	0.063387978,	0.084153005,	0.280874317],
[0.075949367,	0.067510549,	0.066104079,	0.113924051,	0.077355837,	0.078762307,	0.105485232,	0.067510549,	0.108298172,	0.239099859],
[0.064971751,	0.060734463,	0.056497175,	0.097457627,	0.103107345,	0.079096045,	0.104519774,	0.062146893,	0.072033898,	0.299435028],
[0.077531646,	0.068037975,	0.066455696,	0.113924051,	0.083860759,	0.085443038,	0.077531646,	0.071202532,	0.096518987,	0.259493671],
[0.078066914,	0.066914498,	0.063197026,	0.109665428,	0.094795539,	0.117100372,	0.078066914,	0.068773234,	0.079925651,	0.243494424],
[0.074226804,	0.065979381,	0.068041237,	0.115463918,	0.080412371,	0.074226804,	0.084536082,	0.070103093,	0.117525773,	0.249484536],
[0.068965517,	0.068965517,	0.066502463,	0.113300493,	0.088669951,	0.078817734,	0.081280788,	0.064039409,	0.098522167,	0.270935961],
[0.074850299,	0.071856287,	0.068862275,	0.116766467,	0.095808383,	0.086826347,	0.077844311,	0.071856287,	0.095808383,	0.239520958],
[0.080168776,	0.080168776,	0.075949367,	0.130801688,	0.080168776,	0.084388186,	0.084388186,	0.084388186,	0.097046414,	0.202531646],])

x=list()

for i in range(16):
  for j in range(16):
    x=distance.jensenshannon(b[i], b[j], axis=0)
    print(x, '      j=' ,i ,'        j+1=', j)